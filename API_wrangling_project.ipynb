{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data. As a first step, you will need to register a free account on the http://www.quandl.com website. After you register, you will be provided with a unique API key. Simply copy the key from the site (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "API_KEY = 'nkLWzTFsuAkSxhW1YJcA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets.\n",
    "\n",
    "**The Company**\n",
    "\n",
    "- We will focus on _equities data from the **Frankfurt Stock Exhange (FSE)**\n",
    "- Analyze stock prices of a company called **Carl Zeiss Meditec**\n",
    "- Carl Zeiss Meditec manufactures tools for eye examinations as well as medical lasers for laser eye surgery: \n",
    "- Ticker **AFX_X**\n",
    "- company website: https://www.zeiss.com/meditec/int/home.html. \n",
    "\n",
    "\n",
    ">**Quandl API instructions**\n",
    ">>https://docs.quandl.com/docs/time-series\n",
    "\n",
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here:\n",
    "\n",
    ">**Requests**\n",
    ">>http://docs.python-requests.org/en/master/\n",
    "\n",
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy:\n",
    "\n",
    ">**Collections**\n",
    ">>https://pymotw.com/3/collections/ ).\n",
    "\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: \n",
    "\n",
    ">**Python data structures**\n",
    ">>https://docs.python.org/3/tutorial/datastructures.html\n",
    "\n",
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. \n",
    "\n",
    ">_**Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'requests.status_codes' from 'C:\\\\Users\\\\Emtma_000\\\\Anaconda3\\\\lib\\\\site-packages\\\\requests\\\\status_codes.py'>\n",
      "307\n",
      "418\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# First, import the relevant modules\n",
    "import numpy as np\n",
    "import requests\n",
    "import collections\n",
    "\n",
    "# check current status \n",
    "requests.get('https://www.quandl.com/api/v3/datasets/FSE/AFX_X.json?api_key=API_KEY')\n",
    "\n",
    "print(requests.status_codes)\n",
    "\n",
    "print(requests.codes['temporary_redirect'])\n",
    " \n",
    "print(requests.codes.teapot)\n",
    "\n",
    "print(requests.codes['o/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Quandl API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# ... into the JSON structure that will be returned\n",
    "data=requests.get('https://www.quandl.com/api/v3/datasets/FSE/AFX_X.json?api_key=API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab the whole year 2017 for AFX_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the whole year 2017 w/o collapse and transform args\n",
    "myrequest = requests.get('https://www.quandl.com/api/v3/datasets/FSE/AFX_X.json?\\\n",
    "                         column_index=4&start_date=2017-01-01&end_date=2017-12-29&api_key=API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure, note the nesting/structure\n",
    "print(type(myrequest.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Allow': 'GET, HEAD, POST, PUT, DELETE, OPTIONS, PATCH', 'Content-Type': 'application/json; charset=utf-8', 'Date': 'Fri, 12 Jun 2020 11:39:01 GMT', 'Server': 'openresty', 'Connection': 'keep-alive', 'Set-Cookie': 'visid_incap_2261005=WOjs8jwMQaiwbO3f3VAe4FVp414AAAAAQUIPAAAAAAANaJ57+skGvA/3aHSllaNE; expires=Fri, 11 Jun 2021 14:37:39 GMT; HttpOnly; path=/; Domain=.quandl.com; Secure; SameSite=None, nlbi_2261005=9j+WDhyrJQkXBxmJgSMXTwAAAACAw1czgBvLxpur9Gd1RamL; path=/; Domain=.quandl.com; Secure; SameSite=None, incap_ses_113_2261005=vFKQQDlVUlULlLW59HSRAVVp414AAAAAD3tDdpwJfxrVtNFYCUfQEQ==; path=/; Domain=.quandl.com; Secure; SameSite=None', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'X-CDN': 'Incapsula', 'Content-Encoding': 'gzip', 'Transfer-Encoding': 'chunked', 'X-Iinfo': '12-38197609-38197633 NNYY CT(0 0 0) RT(1591961941295 159) q(0 0 0 -1) r(0 0) U11'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check headers\n",
    "myrequest.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/json; charset=utf-8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrequest.headers['Content-Type']    # OR: myrequest.headers.get('content-type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "#check encoding type used default by requests\n",
    "print(myrequest.encoding)\n",
    "\n",
    "# Change type of encoding example\n",
    "#myrequest.encoding = ‘ISO-8859-1’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".text on req obj data-type is <class 'str'>\n",
      "\n",
      "calling .json() on request obj converts to <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# calling text converts request obj to string form \n",
    "print('.text on req obj data-type is {}\\n'.format(type(myrequest.text)))\n",
    "#myrequest.text\n",
    "\n",
    "# requests comes with a built-in JSON decoder\n",
    "# ... note that json format is of dictionary type\n",
    "print('calling .json() on request obj converts to', type(myrequest.json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert request to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names for new query:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "AFXX = requests.get(\"https://www.quandl.com/api/v3/datasets/FSE/AFX_X.json?\\\n",
    "                    start_date=2017-01-01&end_date=2017-12-31&api_key=nkLWzTFsuAkSxhW1YJcA\")\n",
    "# convert to dictionary and select \"dataset\" key\n",
    "AFXX = AFXX.json()['dataset']  #dictionary = myrequest.json()['key']\n",
    "print('column names for new query:\\n{}'.format(AFXX['column_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'dataset_code',\n",
       " 'database_code',\n",
       " 'name',\n",
       " 'description',\n",
       " 'refreshed_at',\n",
       " 'newest_available_date']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "for x in AFXX:\n",
    "    labels.append(x)\n",
    "# all keys as list\n",
    "display(labels[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0]:\n",
      "['2017-12-29', 51.76, 51.94, 51.45, 51.76, None, 34640.0, 1792304.0, None, None, None] \n",
      "\n",
      "\n",
      "(AFX_X) 2017 first day results:\n",
      " Date: 2000-06-07\n",
      " Open: None\n",
      " High: None\n",
      " Low: None\n",
      " Close: 38.0\n",
      " Change: None\n",
      "\n",
      "\n",
      "AFX_X Final trading day 2017 results:\n",
      " Date: 2017-12-28\n",
      " Open: 51.65\n",
      " High: 51.82\n",
      " Low: 51.43\n",
      " Close: 51.6\n",
      " Change: None\n"
     ]
    }
   ],
   "source": [
    "# select data by colling key/label/header name\n",
    "# ... this also converts selection to a list\n",
    "col_names = AFXX['column_names']\n",
    "#Check-type: print('col_names object = {}\\n'.format(type(col_names)))\n",
    "\n",
    "data = AFXX.get('data'); print('data[0]:')\n",
    "print(data[0],'\\n\\n')\n",
    "\n",
    "# vals initial day for 2017 \n",
    "val = [v for v in data[-1]]\n",
    "print('(AFX_X) 2017 first day results:\\n {}: {}\\\n",
    "\\n {}: {}\\n {}: {}\\n {}: {}\\n {}: {}\\n {}: {}\\n'.format(col_names[0], val[0], \n",
    "                                                 col_names[1], val[1] ,col_names[2], val[2], \n",
    "                                                 col_names[3], val[3], col_names[4], val[4],\n",
    "                                                          col_names[5], val[5], col_names[6], val[6]))\n",
    "#results for final trading day 2017\n",
    "vals = [o for o in data[1]]\n",
    "print('\\nAFX_X Final trading day 2017 results:\\n {}: {}\\\n",
    "\\n {}: {}\\n {}: {}\\n {}: {}\\n {}: {}\\n {}: {}'.format(col_names[0], vals[0], \n",
    "                                                 col_names[1], vals[1] ,col_names[2], vals[2], \n",
    "                                                 col_names[3], vals[3], col_names[4], vals[4],\n",
    "                                                 col_names[5], vals[5], col_names[6], vals[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate high and lowest opening price during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build explicit lists of each for entire yr\n",
    "dates = [d[0] for d in list(data)]\n",
    "open_prices = [o[1] for o in data]\n",
    "high_prices = [h[2] for h in data]\n",
    "low_prices = [l[3] for l in data]\n",
    "close_prices = [c[4] for c in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest opening price, 2017: 53.11\n",
      "Lowest opening price, 2017: 4.2\n"
     ]
    }
   ],
   "source": [
    "#opening price high\n",
    "open_prices = np.array(open_prices).astype(np.float)\n",
    "print('highest opening price, 2017: {}'.format(max(open_prices)))\n",
    "#opening price low\n",
    "print('Lowest opening price, 2017: {}'.format(min(open_prices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Largest intraday change for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_flux = np.array(high_prices).astype(np.float) - np.array(low_prices).astype(np.float)\n",
    "price_flux = price_flux.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "largest intraday price increase was 4.39 on 2016-06-24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates_ser = pd.Series(dates)\n",
    "change_ser = pd.Series(price_flux)\n",
    "dates_change = pd.concat([dates_ser, change_ser], \n",
    "                         axis=1).rename(columns={0:'date',\n",
    "                                                 1:'price_flux'})\n",
    "max_intraday_incr = dates_change.price_flux.max()\n",
    "max_intraday_decr = dates_change.price_flux.min()\n",
    "# greatest price change 2017\n",
    "max_intraday_val = round(np.float(dates_change\\\n",
    "                                  [dates_change.price_flux == max_intraday_incr]\\\n",
    "                                  ['price_flux'].values), 2)\n",
    "max_change_date = np.array(dates_change\\\n",
    "                           [dates_change.price_flux == max_intraday_incr]\\\n",
    "                           ['date']).item()\n",
    "print('\\nlargest intraday price increase was {} on {}'.format(max_intraday_val,\n",
    "                                                              max_change_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What was the largest closing price change over 48 hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the largest price change over a 2-day period for 2017 was a loss of $7.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>41.81</td>\n",
       "      <td>-3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>44.37</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>44.96</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  close  change\n",
       "98   2017-08-09  41.81   -3.15\n",
       "99   2017-08-08  44.37   -0.70\n",
       "100  2017-08-07  44.96   -0.01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dates_ser = pd.Series(dates)\n",
    "close_ser = pd.Series(close_prices)\n",
    "dates_close = pd.concat([dates_ser, \n",
    "                         close_ser], axis=1).rename(columns={0:'date', \n",
    "                                                             1:'close'})\n",
    "# percent change process\n",
    "# #round(dates_close.close.pct_change(),3)\n",
    "\n",
    "changes = dates_close.close.diff(periods=-2)\n",
    "largest_change = round(np.max(np.abs(changes)),2)\n",
    "\n",
    "dates_close_change = pd.concat([dates_close.date, dates_close.close, changes], axis=1)\n",
    "dates_close_change.columns = ['date', 'close', 'change']\n",
    "# answer\n",
    "print('the largest price change over a 2-day period for 2017 was a loss of ${}'.format(largest_change))\n",
    "# span\n",
    "dates_close_change[98:101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What was the average daily trading volume during 2017 for AFX_X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average daily trade volume was 47040.76172649196\n"
     ]
    }
   ],
   "source": [
    "data = AFXX.get('data')\n",
    "traded_volume = [c[6] for c in data]\n",
    "print('the average daily trade volume was', np.mean(traded_volume))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
